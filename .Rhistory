# Chunk 4
library(c("data.table", "rjson"))
library(data.table)
require(rjson)
# Chunk 4
library(c("data.table", "rjson"))
list(runif (10), runif(10))
sapply(list(runif (10), runif (10)), function(x) c(min = min(x), mean = mean(x), max = max(x)))
lapply(list(runif (10), runif (10)), function(x) c(min = min(x), mean = mean(x), max = max(x)))
awards <- c("Won 1 Oscar.",
"Won 1 Oscar. Another 9 wins & 24 nominations.",
"1 win and 2 nominations.",
"2 wins & 3 nominations.",
"Nominated for 2 Golden Globes. 1 more win & 2 nominations.",
"4 wins & 1 nomination.")
sub(".*\\s([0-9]+)\\snomination.*$", "\\1", awards)
Sys.data
sys.data
sys.date
sys.date()
Sys.date()
Sys.Date()
# Load Libraries
library(googledrive)
library(readr)
#listings august 2020
data_id <- "1f3L-KHmC89xcn7LIMpGsfwh8zMu8orPE"
out_file <- "data/listings0820.csv"
drive_download(
as_id(data_id),
path = out_file,
overwrite = TRUE)
# Load Libraries
library(googledrive)
library(readr)
#listings august 2020
data_id <- "1f3L-KHmC89xcn7LIMpGsfwh8zMu8orPE"
out_file <- "data/listings0820.csv"
drive_download(
as_id(data_id),
path = out_file,
overwrite = TRUE)
# Load Libraries
library(googledrive)
library(readr)
#listings august 2020
data_id <- "1f3L-KHmC89xcn7LIMpGsfwh8zMu8orPE"
out_file <- "data/listings0820.csv"
drive_download(
as_id(data_id),
path = out_file,
overwrite = TRUE)
#listings august 2020
data_id <- "1f3L-KHmC89xcn7LIMpGsfwh8zMu8orPE"
out_file <- "data/listings0820.csv"
drive_download(
as_id(data_id),
path = out_file,
overwrite = TRUE)
# Load Libraries
library(googledrive)
library(readr)
#listings august 2020
data_id <- "1f3L-KHmC89xcn7LIMpGsfwh8zMu8orPE"
out_file <- "data/listings0820.csv"
drive_download(
as_id(data_id),
path = out_file,
overwrite = TRUE)
#listings august 2020
data_id <- "1f3L-KHmC89xcn7LIMpGsfwh8zMu8orPE"
out_file <- "Master Marketing Analytics/Skills Data/Data Prep/Group Work Data/listings0820.csv"
drive_download(
as_id(data_id),
path = out_file,
overwrite = TRUE)
#Save to file
listings0820 <- read.csv("data/listings0820.csv")
#Save to file
listings0820 <- read.csv("data/listings0820.csv")
#Save to file
listings0820 <- read.csv("data/listings0820.csv")
#Save to file
listings0820 <- read.csv("dMaster Marketing Analytics/Skills Data/Data Prep/Group Work Data/listings0820.csv")
#Save to file
listings0820 <- read.csv("Master Marketing Analytics/Skills Data/Data Prep/Group Work Data/listings0820.csv")
#reviews august 2020
data_id2 <- "1YR7k9ByGnfFqUPs71nzKoFb06_2uWAAy"
out_file2 <- "data/reviews0820.csv"
drive_download(
as_id(data_id2),
path = out_file2,
overwrite = TRUE)
#listings september 2020
data_id3 <- "1M5vfOneYxHe337X6V8xHmoYUXxduN4Gt"
out_file3 <- "Master Marketing Analytics/Skills Data/Data Prep/Group Work Data/listings0920.csv"
drive_download(
as_id(data_id3),
path = out_file3,
overwrite = TRUE)
#Save to file
listings0920 <- read.csv("Master Marketing Analytics/Skills Data/Data Prep/Group Work Data/listings0920.csv")
#listings august 2021
data_id5 <- "11Xy7UtyZaYsOfU4xIDeLA_syv1WFeDV4"
out_file5 <- "data/listings0821.csv"
out_file5 <- "Master Marketing Analytics/Skills Data/Data Prep/Group Work Data/listings0821.csv"
drive_download(
as_id(data_id5),
path = out_file5,
overwrite = TRUE)
#Save to file
listings0821 <- read.csv("Master Marketing Analytics/Skills Data/Data Prep/Group Work Data/listings0821.csv")
#Save to file
listings0821 <- read.csv("Master Marketing Analytics/Skills Data/Data Prep/Group Work Data/listings0821.csv")
View(listings0820)
listings0820$regulation <- 0
listings0821$regulation <- 1
View(listings0821)
listings0820$regulation <- 0
listings0821$regulation <- 1
merge(listings0820, listings0821)
listings_merged <- merge(listings0820, listings0821)
listings_merged <- merge(listings0820, listings0821, all.x=TRUE, all.y=TRUE)
View(listings_merged)
#Make dummy variable a factor
listings_merged$regulation <- as.factor(listings_merged$regulation)
listings_merged <- merge(listings0820, listings0821, all.x=TRUE, all.y=TRUE)
summary(listings_merged)
#Make dummy variable a factor
listings_merged$regulation <- as.factor(listings_merged$regulation)
summary(listings_merged)
save(listings_merged)
library(gapminder)
library(dplyr)
library(reshape2)
install.packages("reshape2")
library(dplyr)
library(reshape2)
######################
### DOWNLOAD DATA ####
######################
download_data <- function(url, filename){
download.file(url = url, destfile = paste0(filename, ".csv"))
}
url_listings <- "http://data.insideairbnb.com/belgium/vlg/antwerp/2021-02-25/visualisations/listings.csv"
url_reviews <- "http://data.insideairbnb.com/belgium/vlg/antwerp/2021-02-25/visualisations/reviews.csv"
download_data(url_listings, "listings")
download_data(url_reviews, "reviews")
######################
#### CLEAN DATA ######
######################
reviews <- read.csv("reviews.csv")
listings <- read.csv("listings.csv")
# convert date column
reviews$date <- as.Date(reviews$date)
# filter for reviews published since 01/01/2015
reviews_filtered <- reviews %>% filter(date > "2015-01-01")
# filter for `listings` that have received at least 1 review.
listings_filtered <- listings %>% filter(number_of_reviews > 1)
# merge the `reviews` and `listings` dataframes on a common columns (the type of join doesn't really matter since we already filtered out listings without any reviews)
df_merged <- reviews_filtered %>%
inner_join(listings_filtered, by = c("listing_id" = "id"))
# group the number of reviews by month and neighborhood.
df_grouped <- df_merged %>%
mutate(month = format(date, "%m"), year = format(date, "%Y")) %>%
group_by(year, month, neighbourhood) %>%
summarise(num_reviews = n())
# create date column
df_grouped$date <- as.Date(paste0(df_grouped$year, "-", df_grouped$month, "-01"))
# store the final data frame in `gen/data-preparation` as `aggregated_df.csv`
write.csv(df_grouped, "aggregated_df.csv")
# import the data from `gen/data-preparation/aggregated_df.csv`
df <- read.csv("aggregated_df.csv")
# create pivot table
df_pivot <- df %>% dcast(date ~ neighbourhood, fun.aggregate = sum, value.var = "num_reviews")
# export results
write.csv(df_pivot, "pivot_table.csv")
# import the data from `gen/analysis/pivot_table`
df_pivot <- read.csv("pivot_table.csv")
# convert the `date` column into date format.
df_pivot$date <- as.Date(df_pivot$date)
pdf("plot_Antwerp.pdf")
plot(x = df_pivot$date,
y = df_pivot$Universiteitsbuurt,
col = "red",
type = "l",
xlab = "",
ylab = "Total number of reviews",
main = "Effect of COVID-19 pandemic on Airbnb review count")
lines(df_pivot$date, df_pivot$Sint.Andries, col="blue")
lines(df_pivot$date, df_pivot$Centraal.Station, col="green")
legend("topleft", c("Universiteitsbuurt", "Sint Andries", "Centraal Station"), fill=c("red", "blue", "green"))
dev.off()
# import the data from `gen/data-preparation/aggregated_df.csv`
df <- read.csv("aggregated_df.csv")
# convert the `date` column into date format.
df$date <- as.Date(df$date)
# group by date and calculate the sum of all reviews across neighbourhoods.
df_groupby <- df %>% group_by(date) %>% summarise(num_reviews = sum(num_reviews))
# plot the chart and store the visualisation.
pdf("plot_all.pdf")
plot(x = df_groupby$date,
y = df_groupby$num_reviews,
type = "l",
xlab = "",
ylab = "Total number of reviews",
main = "Effect of COVID-19 pandemic on Airbnb review count")
dev.off()
library(dplyr)
library(reshape2)
.libPaths()
library(dplyr)
library(reshape2)
######################
### DOWNLOAD DATA ####
######################
download_data <- function(url, filename){
download.file(url = url, destfile = paste0(filename, ".csv"))
}
url_listings <- "http://data.insideairbnb.com/belgium/vlg/antwerp/2021-02-25/visualisations/listings.csv"
url_reviews <- "http://data.insideairbnb.com/belgium/vlg/antwerp/2021-02-25/visualisations/reviews.csv"
download_data(url_listings, "listings")
download_data(url_reviews, "reviews")
library(dplyr)
library(reshape2)
# create date column
df_grouped$date <- as.Date(paste0(df_grouped$year, "-", df_grouped$month, "-01"))
# store the final data frame in `gen/data-preparation` as `aggregated_df.csv`
write.csv(df_grouped, "aggregated_df.csv")
######################
# CREATE PIVOT TABLE #
######################
# import the data from `gen/data-preparation/aggregated_df.csv`
df <- read.csv("aggregated_df.csv")
# create pivot table
df_pivot <- df %>% dcast(date ~ neighbourhood, fun.aggregate = sum, value.var = "num_reviews")
# export results
write.csv(df_pivot, "pivot_table.csv")
library(dplyr)
library(reshape2)
######################
# CREATE PIVOT TABLE #
######################
# import the data from `gen/data-preparation/aggregated_df.csv`
df <- read.csv("aggregated_df.csv")
# create pivot table
df_pivot <- df %>% dcast(date ~ neighbourhood, fun.aggregate = sum, value.var = "num_reviews")
# export results
write.csv(df_pivot, "pivot_table.csv")
library(dplyr)
library(reshape2)
######################
### PLOT ANTWERP ####
######################
# import the data from `gen/analysis/pivot_table`
df_pivot <- read.csv("pivot_table.csv")
# convert the `date` column into date format.
df_pivot$date <- as.Date(df_pivot$date)
pdf("plot_Antwerp.pdf")
plot(x = df_pivot$date,
y = df_pivot$Stadspark,
col = "red",
type = "l",
xlab = "",
ylab = "Total number of reviews",
main = "Effect of COVID-19 pandemic on Airbnb review count")
lines(df_pivot$date, df_pivot$Sint.Andries, col="blue")
lines(df_pivot$date, df_pivot$Centraal.Station, col="green")
legend("topleft", c("Stadspark", "Sint Andries", "Centraal Station"), fill=c("red", "blue", "green"))
dev.off()
library(dplyr)
library(reshape2)
######################
##### PLOT ALL #######
######################
# import the data from `gen/data-preparation/aggregated_df.csv`
df <- read.csv("aggregated_df.csv")
# convert the `date` column into date format.
df$date <- as.Date(df$date)
# group by date and calculate the sum of all reviews across neighbourhoods.
df_groupby <- df %>% group_by(date) %>% summarise(num_reviews = sum(num_reviews))
# plot the chart and store the visualisation.
pdf("plot_all.pdf")
plot(x = df_groupby$date,
y = df_groupby$num_reviews,
type = "l",
xlab = "",
ylab = "Total number of reviews",
main = "Effect of COVID-19 pandemic on Airbnb review count")
dev.off()
.libPaths()
library(dplyr)
library(reshape2)
# import the data from `gen/temp/aggregated_df.csv`
df <- read.csv("gen/temp/aggregated_df.csv")
install.packages("haven")
library(haven)
setwd("C:/Users/Marit Verbruggen/Documents/Master Marketing Analytics/Intro to MM/R-files/Tutorial 7 Week 7")
stores <- read_sav("stores.sav")
View(stores)
summary(stores)
# Check multicollinearity
library(corrplot)
corrplot(cor(stores[,5:12]), method="number")
# Remove education hi
stores <- stores[,-10]
#Hierarchical clustering
#Ward's method
stores_hc <- hclust(dist(stores[,5:11], method="euclidean"), method="ward.D2")
# Agglomeration schedule
data.frame(stores_hc$merge)
#Dendogram
install.packages("factoextra")
library(factoextra)
fviz_dend(stores_hc, k=1, horiz=TRUE)
#Elbow plot
fviz_nbclust(stores[,5:11], FUNcluster=hcut, method="wss")
#Assign stores to clusters, now 3
stores <- cbind(stores, cluster_hc=cutree(stores_hc, k=3))
#Number of stores per cluster
table(stores$cluster_hc)
library(dplyr)
stores_centroids <- stores %>% select(agehh, twoworks, homeowne, hhsize, educlow, urban, incomehi, cluster_hc) %>% group_by(cluster_hc) %>% summarize_all(list(mean))
View(stores_centroids)
# K-means
set.seed(123)
stores_km <- kmeans(stores[,5:11], centers=stores_centroids[,-1], nstart=25)
# Assign stores to clusters
stores <- cbind(stores, cluster_km=stores_km$cluster)
stores_km$size
View(stores_km)
# Group means
stores_km_means <- stores %>% select(agehh, twoworks, homeowne, hhsize, educlow, urban, incomehi, cluster_km) %>% group_by(cluster_km) %>% summarize_all(list(mean))
t(data.frame(stores_km_means[,-1]))
# Are there clusters related to store size?
stores_ct <- table(stores$stsize, stores$cluster_km)
stores_ct
summary(stores_ct)
setwd("~/Master Marketing Analytics/Intro to MM/R-files/Assignment Files")
library(haven)
stores <- read.csv("store.csv")
stores <- read_sav("stores.sav")
View(stores)
#create subset
stores_sub <- stores %>% filter(area != 2)
View(stores_sub)
#create subset
stores <- stores %>% filter(area != 2)
View(stores_sub)
stores <- stores(-c[10])
stores <- subset(stores, select = -c[10])
stores <- subset(stores, select = -c(10))
stores <- stores[,-10]
library(haven)
stores <- read_sav("stores.sav")
View(stores)
#create subset
stores <- stores %>% filter(area != 2)
stores <- stores[,-10]
#Ward's method
stores_hc <- hclust(dist(stores[,5:11], method="euclidean"), method="ward.D2")
# Agglomeration schedule
data.frame(stores_hc$merge)
library(factoextra)
fviz_dend(stores_hc, k=1, horiz=TRUE)
fviz_dend(stores_hc, k=3, horiz=TRUE)
#Elbow plot
fviz_nbclust(stores[,5:11], FUNcluster=hcut, method="wss")
#Assign stores to clusters, now 3
stores <- cbind(stores, cluster_hc=cutree(stores_hc, k=3))
table(stores$cluster_hc)
library(dplyr)
stores_centroids <- stores %>% select(agehh, twoworks, homeowne, hhsize, educlow, urban, incomehi, cluster_hc) %>% group_by(cluster_hc) %>% summarize_all(list(mean))
View(stores_centroids)
stores_centroids$educlow = as.factor(stores_centroids$educlow)
#Linear regression
Regression <- lm(educlow ~ cluster_hc, stores_centroids)
stores_centroids$cluster_hc = as.factor(stoes_centroids$cluster_hc)
stores_centroids$cluster_hc = as.factor(stores_centroids$cluster_hc)
#Linear regression
Regression <- lm(educlow ~ cluster_hc, stores_centroids)
stores_centroids$educlow = as.numeric(stores_centroids$educlow)
stores_centroids$cluster_hc = as.numeric(stores_centroids$cluster_hc)
#Linear regression
Regression <- lm(educlow ~ cluster_hc, stores_centroids)
anova(Regression)
set.seed(123)
stores_km <- kmeans(stores[,5:11], centers=stores_centroids[,-1], nstart=25)
stores <- cbind(stores, cluster_km=stores_km$cluster)
stores_km$size
stores_km_means <- stores %>% select(agehh, twoworks, homeowne, hhsize, educlow, urban, incomehi, cluster_km) %>% group_by(cluster_km) %>% summarize_all(list(mean))
t(data.frame(stores_km_means[,-1]))
stores_km_means <- stores %>% select(educlow, cluster_km) %>% group_by(cluster_km) %>% summarize_all(list(mean))
t(data.frame(stores_km_means[,-1]))
regression <- lm(educlow ~ cluster_km, stores_km_means)
anova(regression)
stores_km_means <- stores %>% select(agehh, twoworks, homeowne, hhsize, educlow, urban, incomehi, cluster_km) %>% group_by(cluster_km) %>% summarize_all(list(mean))
t(data.frame(stores_km_means[,-1]))
regression <- lm(educlow ~ cluster_km, stores_km_means)
anova(regression)
regression_1 <- lm(revenue ~ clusters+surface, stores_km_means)
stores_km_means <- stores %>% select(agehh, twoworks, homeowne, hhsize, educlow, urban, incomehi, revenue, cluster_km) %>% group_by(cluster_km) %>% summarize_all(list(mean))
t(data.frame(stores_km_means[,-1]))
regression <- lm(educlow ~ cluster_km, stores_km_means)
anova(regression)
regression_1 <- lm(revenue ~ clusters+surface, stores_km_means)
regression_1 <- lm(revenue ~ cluster_km+surface, stores_km_means)
stores_km_means <- stores %>% select(agehh, twoworks, homeowne, hhsize, educlow, urban, incomehi, revenue, surface, cluster_km) %>% group_by(cluster_km) %>% summarize_all(list(mean))
t(data.frame(stores_km_means[,-1]))
regression <- lm(educlow ~ cluster_km, stores_km_means)
anova(regression)
regression_1 <- lm(revenue ~ cluster_km+surface, stores_km_means)
anova(regression_1)
summary(stores_km_means)
regression_1 <- lm(revenue ~ cluster_km+surface, stores_km_means)
anova(regression_1)
stores_km_means$cluster_km < as.factor(stores_km_means$cluster_km)
regression_1 <- lm(revenue ~ cluster_km+surface, stores_km_means)
anova(regression_1)
regression_1 <- lm(revenue ~ cluster_km+surface, stores_km_means)
anova(regression_1)
stores_km_means <- stores %>% select(agehh, twoworks, homeowne, hhsize, educlow, urban, incomehi, revenue, surface, cluster_km) %>% group_by(cluster_km) %>% summarize_all(list(mean))
t(data.frame(stores_km_means[,-1]))
regression <- lm(educlow ~ cluster_km, stores_km_means)
anova(regression)
regression_1 <- lm(revenue ~ cluster_km+surface, stores_km_means)
anova(regression_1)
class(stores_km_means$surface)
regression_1 <- lm(revenue ~ cluster_km*surface, stores_km_means)
anova(regression_1)
regression_1 <- lm(revenue ~ cluster_km, stores_km_means)
anova(regression_1)
regression_1 <- lm(revenue ~ cluster_km+surface, stores_km_means)
anova(regression_1)
regression_1 <- lm(revenue ~ cluster_km, stores_km_means)
anova(regression_1)
regression <- lm(educlow ~ cluster_km, stores)
anova(regression)
regression_1 <- lm(revenue ~ cluster_km+surface, stores)
anova(regression_1)
# Load the data
all_data <- read.csv(file = 'all_regions_data.csv')
setwd("~/Master Marketing Analytics/Skills Data/Data Coll&Mgt/Vivino Webscraper/Vivino_webscraper")
# Load package
library(dplyr)
# Load the data
all_data <- read.csv(file = 'all_regions_data.csv')
# Check for any anomalities
summary(all_data)
# Change Average.Rating into a numerical variable
all_data$Average.Rating <- (gsub("\\,", ".", all_data$Average.Rating))
all_data$Average.Rating <- as.numeric(all_data$Average.Rating)
# Check whether it worked
is.numeric(all_data$Average.Rating)
# Check for any anomalities
View(all_data)
# Change Average.Rating into a numerical variable
all_data$average_rating <- (gsub("\\,", ".", all_data$Average.Rating))
# Change Average.Rating into a numerical variable
all_data$average_rating <- (gsub("\\,", ".", all_data$average.rating))
# Change Average.Rating into a numerical variable
all_data$average_rating <- (gsub("\\,", ".", all_data$average_rating))
all_data$average_rating <- as.numeric(all_data$average.rating)
# Check whether it worked
is.numeric(all_data$Average.Rating)
# Check whether it worked
is.numeric(all_data$average_rating)
# Change Average.Rating into a numerical variable
all_data$average_rating <- (gsub("\\,", ".", all_data$average_rating))
all_data$average_rating <- as.numeric(all_data$average_rating)
# Check whether it worked
is.numeric(all_data$average_rating)
# Get rid of columns that don't matter to us
all_data <- all_data[, c(2, 4:7)]
# Get rid of columns that don't matter to us
all_data <- all_data[, c(3:7)]
# Get rid of columns that don't matter to us
all_data <- all_data[, c(3:6)]
# Load the data
all_data <- read.csv(file = 'all_regions_data.csv')
# Check for any anomalities
View(all_data)
summary(all_data)
# Change Average.Rating into a numerical variable
all_data$average_rating <- (gsub("\\,", ".", all_data$average_rating))
all_data$average_rating <- as.numeric(all_data$average_rating)
# Check whether it worked
is.numeric(all_data$average_rating)
# Get rid of columns that don't matter to us
all_data <- all_data[, c(2:6)]
# Make dummy variables
all_data$bordeaux <- as.numeric(all_data$Region == "Bordeaux")
all_data$bourgogne <- as.numeric(all_data$Region == "Bourgogne")
all_data$napa_valley <- as.numeric(all_data$Region == "Napa Valley")
all_data$piemonte <- as.numeric(all_data$Region == "Piemonte")
all_data$rhone_valley <- as.numeric(all_data$Region == "Rhone Valley")
all_data$toscana <- as.numeric(all_data$Region == "Toscana")
# Make dummy variables
all_data$bordeaux <- as.numeric(all_data$region == "Bordeaux")
all_data$bourgogne <- as.numeric(all_data$region == "Bourgogne")
all_data$napa_valley <- as.numeric(all_data$region == "Napa Valley")
all_data$piemonte <- as.numeric(all_data$region == "Piemonte")
all_data$rhone_valley <- as.numeric(all_data$region == "Rhone Valley")
all_data$toscana <- as.numeric(all_data$region == "Toscana")
sum(is.na(all_data$number_of_ratings))
sum(is.na(all_data$average_rating))
# Check for NAs
sum(is.na(all_data$region))
sum(is.na(all_data$number_of_ratings))
sum(is.na(all_data$average_rating))
# Mean of every region
all_data %>% group_by(region) %>% summarize(average_rating = mean(average_rating))
